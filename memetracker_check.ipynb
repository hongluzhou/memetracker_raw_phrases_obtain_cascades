{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhttps://snap.stanford.edu/data/memetracker9.html\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://snap.stanford.edu/data/other.html\n",
    "\n",
    "https://snap.stanford.edu/data/memetracker9.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utc_timestamp(timestamp):\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    base_timestep = datetime.datetime(1970, 1, 1)\n",
    "    timestamp = dt.strptime(timestamp, time_format)\n",
    "    curr_utc = int((timestamp - base_timestep).total_seconds())\n",
    "    return curr_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550501\n",
      "[172946, 70131, 58245, 42285, 41224, 39922, 37186, 29567, 28059, 25924]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "with gzip.open('./raw/memetracker/quotes_2008-08.txt.gz','rt') as f:\n",
    "    for line in f:\n",
    "        lines.append(line)\n",
    "\n",
    "# check P and occurance\n",
    "P_oc = dict()\n",
    "for line in lines:\n",
    "    if line == '\\n':\n",
    "        continue\n",
    "    [tag, content] = line.split('\\n')[0].split('\\t')\n",
    "    if tag == 'P':\n",
    "        site = content.split('http://')[1].split('/')[0]\n",
    "        try:\n",
    "            P_oc[site] += 1\n",
    "        except KeyError:\n",
    "            P_oc[site] = 1\n",
    "\n",
    "sort_p_oc = sorted(list(P_oc.values()), reverse=True)           \n",
    "print(len(sort_p_oc))\n",
    "print(sort_p_oc[:10])\n",
    "print(sort_p_oc[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of websites are 550501\n",
    "* The largest number of website frequency can be 172946\n",
    "* The smallest number of website frequency can be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(np.where(numpy.array(sort_p_oc)>10000)[0]))\n",
    "print(len(np.where(numpy.array(sort_p_oc)>1000)[0]))\n",
    "np.where(numpy.array(sort_p_oc)>10000)[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7340810\n"
     ]
    }
   ],
   "source": [
    "# check P and occurance\n",
    "raw_P = set()\n",
    "for line in lines:\n",
    "    if line == '\\n':\n",
    "        continue\n",
    "    [tag, content] = line.split('\\n')[0].split('\\t')\n",
    "    if tag == 'P':\n",
    "        raw_P.add(content)\n",
    "        \n",
    "print(len(raw_P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of posts with information provided are 7340810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8813559\n",
      "[31287, 22948, 19328, 11149, 10543, 10413, 10152, 10152, 9279, 8948]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# check Q and occurance\n",
    "Q_oc = dict()\n",
    "for line in lines:\n",
    "    if line == '\\n':\n",
    "        continue\n",
    "    [tag, content] = line.split('\\n')[0].split('\\t')\n",
    "    if tag == 'Q':\n",
    "        try:\n",
    "            Q_oc[content] += 1\n",
    "        except KeyError:\n",
    "            Q_oc[content] = 1\n",
    "\n",
    "sort_q_oc = sorted(list(Q_oc.values()), reverse=True)           \n",
    "print(len(sort_q_oc))\n",
    "print(sort_q_oc[:10])\n",
    "print(sort_q_oc[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of phrases are 8813559\n",
    "* The largest number of phrase frequency can be 31287\n",
    "* The smallest number of phrase frequency can be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9397791\n",
      "[214062, 211698, 86214, 84251, 84222, 60849, 60212, 45442, 38116, 35406]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# check L and occurance\n",
    "L_oc = dict()\n",
    "for line in lines:\n",
    "    if line == '\\n':\n",
    "        continue\n",
    "    [tag, content] = line.split('\\n')[0].split('\\t')\n",
    "    if tag == 'L':\n",
    "        try:\n",
    "            L_oc[content] += 1\n",
    "        except KeyError:\n",
    "            L_oc[content] = 1\n",
    "\n",
    "sort_l_oc = sorted(list(L_oc.values()), reverse=True)           \n",
    "print(len(sort_l_oc))\n",
    "print(sort_l_oc[:10])\n",
    "print(sort_l_oc[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of linked posts are 9397791\n",
    "* The largest number of linked post frequency can be 214062\n",
    "* The smallest number of linked post frequency can be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583623\n"
     ]
    }
   ],
   "source": [
    "raw_L = set(list(L_oc.keys()))\n",
    "tem = raw_P.intersection(raw_L)\n",
    "print(len(tem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of posts with detailed information and being linked are 583623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can form memes dataset and links dataset (citation network).   \n",
    "   \n",
    "site2userid   \n",
    "userid2site \n",
    "\n",
    "blogurl2userid   \n",
    "userid2blogurl   \n",
    "   \n",
    "notes in graph:   \n",
    "user == site   \n",
    "url == blog   \n",
    "   \n",
    "meme: [cascade from sourcesite to end]    \n",
    "blog, time, sourcesite, meme   \n",
    "   \n",
    "mentionedblog: [cascade from sourceblog to end]    \n",
    "blog, time, sourceblog, mentionedblog, mentionedbloguser   \n",
    "   \n",
    "site_frequency   \n",
    "blog_frequency   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====== START processing =====   \n",
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./raw/memetracker/quotes_2008-08.txt.gz']\n",
      "starting reading raw files\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "# files = [file for file in os.listdir('./raw/memetracker') if '.txt.gz' in file]\n",
    "files = ['./raw/memetracker/quotes_2008-08.txt.gz']\n",
    "print(files)\n",
    "\n",
    "print(\"starting reading raw files\")\n",
    "lines = []\n",
    "count = 0\n",
    "for file in files:\n",
    "    with gzip.open(file,'rt') as f:\n",
    "        for line in f:\n",
    "            lines.append(line)\n",
    "    count += 1\n",
    "    print(count, len(files))\n",
    "    if count == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* meme cascades    \n",
    "get all sites frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of sites:\n",
      "550501\n",
      "top 10 sites frequency:\n",
      "[172946, 70131, 58245, 42285, 41224, 39922, 37186, 29567, 28059, 25924]\n"
     ]
    }
   ],
   "source": [
    "site_frequency = dict()\n",
    "\n",
    "for line in lines:\n",
    "    if line == '\\n':\n",
    "        continue\n",
    "    [tag, content] = line.split('\\n')[0].split('\\t')\n",
    "    if tag == 'P':\n",
    "        site = content.split('http://')[1].split('/')[0]\n",
    "        try:\n",
    "            site_frequency[site] += 1\n",
    "        except KeyError:\n",
    "            site_frequency[site] = 1\n",
    "\n",
    "sort_site_frequency = sorted(list(site_frequency.values()), reverse=True) \n",
    "print('the number of sites:')\n",
    "print(len(site_frequency))\n",
    "print('top 10 sites frequency:')\n",
    "print(sort_site_frequency[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "6023\n",
      "6023\n"
     ]
    }
   ],
   "source": [
    "site2userid = dict()\n",
    "userid2site = dict()\n",
    "\n",
    "threshold = sort_site_frequency[6000 + 1]\n",
    "for site in site_frequency:\n",
    "    if site_frequency[site] >= threshold:\n",
    "        userid2site[len(site2userid)] = site\n",
    "        site2userid[site] = len(site2userid)\n",
    "print(threshold)\n",
    "print(len(userid2site))\n",
    "print(len(site2userid))\n",
    "\n",
    "allsites = set(list(site2userid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4170881\n"
     ]
    }
   ],
   "source": [
    "blogs_start_line_idx = []\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i]\n",
    "    if line == '\\n':\n",
    "        continue\n",
    "    else:\n",
    "        [tag, content] = line.split('\\n')[0].split('\\t')\n",
    "        if tag == 'P':\n",
    "            site = content.split('http://')[1].split('/')[0]\n",
    "            if site in allsites:\n",
    "                blogs_start_line_idx.append(i)\n",
    "\n",
    "print(len(blogs_start_line_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_start_line_idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Q and occurance\n",
    "Q_oc = dict()\n",
    "for line in lines:\n",
    "    if line == '\\n':\n",
    "        continue\n",
    "    [tag, content] = line.split('\\n')[0].split('\\t')\n",
    "    if tag == 'Q':\n",
    "        try:\n",
    "            Q_oc[content] += 1\n",
    "        except KeyError:\n",
    "            Q_oc[content] = 1\n",
    "\n",
    "sort_q_oc = sorted(list(Q_oc.values()), reverse=True)           \n",
    "print(len(sort_q_oc))\n",
    "print(sort_q_oc[:10])\n",
    "print(sort_q_oc[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_cascades = dict()\n",
    "meme_cascades['meme'] = []\n",
    "meme_cascades['time'] = []\n",
    "meme_cascades['site'] = []\n",
    "memes_frequency = dict()\n",
    "\n",
    "for i in range(len(blogs_start_line_idx)):\n",
    "    idx = blogs_start_line_idx[i]\n",
    "    try:\n",
    "        next_idx = blogs_start_line_idx[i+1]\n",
    "    except IndexError:\n",
    "        next_idx = len(lines)\n",
    "    blogmemes = []\n",
    "    # print(idx, next_idx)\n",
    "    # print(lines[idx])\n",
    "    # print(lines[next_idx])\n",
    "    \n",
    "    for blogidx in range(idx, next_idx-1):\n",
    "        line = lines[blogidx]\n",
    "        if line == '\\n':\n",
    "            break\n",
    "        [tag, content] = line.split('\\n')[0].split('\\t')\n",
    "        # print(line)\n",
    "        if tag == 'P':\n",
    "            site = content.split('http://')[1].split('/')[0]\n",
    "        if tag == 'Q':\n",
    "            blogmemes.append(content)\n",
    "        if tag == 'T':\n",
    "            blogtime = content\n",
    "    # print(len(blogmemes))\n",
    "    for meme in blogmemes:\n",
    "        meme_cascades['meme'].append(meme)\n",
    "        meme_cascades['time'].append(blogtime)\n",
    "        meme_cascades['site'].append(site)\n",
    "        try:\n",
    "            memes_frequency[meme] += 1\n",
    "        except KeyError:\n",
    "            memes_frequency[meme] = 1\n",
    "    # print(meme_cascades['meme'])\n",
    "    # print(meme_cascades['time'])\n",
    "    # print(meme_cascades['site'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of memes:\n",
      "4534651\n",
      "top 10 memes frequency:\n",
      "[31287, 22848, 19328, 10543, 10413, 10152, 10152, 9279, 8948, 8948]\n",
      "last 10 memes frequency:\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "sort_memes_frequency = sorted(list(memes_frequency.values()), reverse=True) \n",
    "print('the number of memes:')\n",
    "print(len(memes_frequency))\n",
    "print('top 10 memes frequency:')\n",
    "print(sort_memes_frequency[:10])\n",
    "print('last 10 memes frequency:')\n",
    "print(sort_memes_frequency[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11377848\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(meme_cascades)       \n",
    "df.to_csv(os.path.join('./data/', \"cascades_meme.csv\"), index=False)\n",
    "print(len(df))\n",
    "df['time']=pd.to_datetime(df['time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df.sort_values(by=['time'], inplace=True, ascending=True)\n",
    "df.to_csv(os.path.join('./data/', \"cascades_meme2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well maybe because you'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meme = pd.DataFrame(df.get_group('well maybe because you'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meme.sort_values(by=['time'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meme</th>\n",
       "      <th>time</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11377847</th>\n",
       "      <td>well maybe because you</td>\n",
       "      <td>2008-08-31 23:59:53</td>\n",
       "      <td>statueforum.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            meme                time             site\n",
       "11377847  well maybe because you 2008-08-31 23:59:53  statueforum.com"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meme.drop_duplicates('site')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well maybe because you']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_meme['meme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honglu_py3",
   "language": "python",
   "name": "honglu_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
